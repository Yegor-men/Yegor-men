# About Me
I'm interested in Data Science, largely in Artificial intelligence, but more specifically in Machine Learning and especially Deep Learning.

I haven't yet attended univerisity, so everything here is self taught from the resources I could find. I am always willing to learn more/extra and plan on continuing to do so.

# Roadmap / Goals / Interests
- Reinforcement Learning
- Arbitrary length sequential encoding
- Latent space reasoning
- Non proprietary reliant frameworks

# Contact
I am open to collaboration, you can contact me via

Email (yegor.mn@gmail.com) | [LinkedIn](https://www.linkedin.com/in/yegor-menovchshikov-313150350/) | [Twitter / X](https://x.com/Yegor_Men) | [Bluesky](https://bsky.app/profile/yegormen.bsky.social)

# My projects

## Currently working on:
- [Variable autoencoder](https://github.com/Yegor-men/vae) - Various VAE architectures, largely aiming to recreate the Stable Diffusion VAEs but also wanting to create a 16x height/width reduction vae to be used on 2MP+ images with fast inference and accurate reconstruction
- [Tic Tac Toe with reinfocement learning](https://github.com/Yegor-men/tic-tac-toe-rl) - A model that can play Tic Tac Toe learnt entirely through reinforcement learning

## Future projects:
- [GPT2 recreation](https://github.com/Yegor-men/gpt2) - A recreation of the GPT2 architecture
- Small LMs - Small language models of various architectures but recreated with my own code from scratch
- [Stable Diffusion recreation](https://github.com/Yegor-men/sd15) - A recreation of the Stable Diffusion 1.5 architecture/model
- Diffusions - Various diffusion based models of various arhcitectures but recreated with my own code from scratch
- [Sequential frame by frame video encoding](https://github.com/Yegor-men/sequential-video-encode) - A model that is to encode a video of arbitrary length into a fixed size latent space via sequential frame by frame encoding
- Sequential token by token text encoding - A model that is to encode a text of arbitrary length into a fixed latent space via sequential token by token encoding
- Realtime screen analysis and response model - A model that continuously takes in screenshots, its own internal monologue and produces some cohesive output. Designed to be as a form of autonomous agent with free reign

## Completed (I will not be going back to this / very little updates)
- [Iris classification](https://github.com/Yegor-men/iris-classification) - A model trained on the Iris classification dataset
- [MNIST](https://github.com/Yegor-men/mnist) - A series of models trained on the MNIST type datasets
- [Harmonic Loss paper](https://github.com/Yegor-men/harmonic-loss) - My implementation of the harmonic loss paper and other experiments based on using euclidean distance as probabilities
- [Sequential encode tests](https://github.com/Yegor-men/sequential-encode-tests) - My (very) naive and early attempts at creating sequential encoding models
- [Pytorch learning course made by Daniel Bourke](https://github.com/Yegor-men/learning-pytorch-from-daniel-bourke) - My repo for following along with Daniel Bourke's pytorch learning course
- [Neural nets in raw python](https://github.com/Yegor-men/raw-python-neural-nets) - My earliest project where I made neural nets without libraries and with only numpy


<!--
**Yegor-men/Yegor-men** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
